{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5P+YccvG0+uGlvl5MHgjB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohaibabdullah/PyTorch-Essentials/blob/main/PyTorch_Tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial on PyTorch Tensors\n",
        "PyTorch tensors are multidimensional arrays and serve as a foundational data strucure in pyTorch."
      ],
      "metadata": {
        "id": "h_7J9wF3bmaE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a 4x3 pyTorch Tensor with Zeros"
      ],
      "metadata": {
        "id": "-LaNWT0bbuiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "w = torch.zeros(4,3)\n",
        "print(w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNfKGC0CbtnT",
        "outputId": "1a2a7a6c-8b71-4040-f0d8-a8646904d83a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.size() # Looking into the size of the tensor w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYUgFhhXcvjD",
        "outputId": "93054ad2-529d-442e-b209-e56baef44861"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.shape # Same thing can be doen using 'Shape' just like numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BOwW-TcdQ-C",
        "outputId": "787a94fc-60a1-46eb-f022-c407c0580c5a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Values\n",
        "Random values can be assigned from Standard Normal Distribution (i.e., mean=0, standard deviation = 1) using randn where 'n' after the word 'rand' stands for standar normal distribution."
      ],
      "metadata": {
        "id": "Z23kOggMdnPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.randn(4,3)\n",
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws5m2VTLeQEj",
        "outputId": "15e9dae0-c2fb-4d32-8371-b2537116bddb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.8514, -0.7976,  1.0033],\n",
              "        [-0.0495,  0.9149,  0.6243],\n",
              "        [-0.1906, -0.8557, -0.6325],\n",
              "        [ 0.2027, -1.9795,  2.0647]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.randn_like(w) # using randn to create a new tensor t with dimension like w\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H7GxLn0fp9N",
        "outputId": "a7ab91fd-2501-4dc7-eba6-1fbbe1e9a817"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2935,  0.3555,  1.1461],\n",
              "        [-2.4822,  0.9152,  0.3846],\n",
              "        [ 0.6491, -0.0698, -0.9012],\n",
              "        [-0.5294,  0.7389, -1.1575]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fill, Reshape and Converting to **numpy**"
      ],
      "metadata": {
        "id": "l4TklRXwfXq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w.fill_(1) # Replace the values of tensor w with 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJCgHRXzffgU",
        "outputId": "ba813503-7917-4d74-db58-1de2d0028719"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = w.view(3,4) # Reshape the tensor w to 3x4 (Previous diemnsion was 4x3)\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4WYwetWf7JQ",
        "outputId": "ff88fedf-9076-4dda-ec76-9372377d40a2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.8514, -0.7976,  1.0033, -0.0495],\n",
              "        [ 0.9149,  0.6243, -0.1906, -0.8557],\n",
              "        [-0.6325,  0.2027, -1.9795,  2.0647]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.numpy() # Converting the torch tensor w into numpy array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgmEKZlcgR-f",
        "outputId": "1de411e3-17a7-41df-f1ab-95a3904f5fa8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.8513522 , -0.797558  ,  1.0032926 ],\n",
              "       [-0.04947498,  0.9149364 ,  0.6242651 ],\n",
              "       [-0.19061683, -0.8557128 , -0.63253   ],\n",
              "       [ 0.20274882, -1.9795147 ,  2.064721  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Images as PyTorch Tensors"
      ],
      "metadata": {
        "id": "JdWEwk4Ugulj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = torch.rand((4,28,28)) # Creating 4 random images with dimension 28x28"
      ],
      "metadata": {
        "id": "AFYtZPWlgiAv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_image = images[1] # Assigning second of the 4 images into second_image\n",
        "second_image # viewing the random pixel values of 28x28 pyTorch tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5jK_vPshMtl",
        "outputId": "b1560627-2d30-472e-c828-617d6b1fd236"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.4213e-01, 1.7668e-01, 1.8978e-01, 7.8381e-01, 9.5804e-01, 8.7392e-02,\n",
              "         6.8892e-02, 7.8307e-01, 5.6004e-01, 5.2798e-01, 1.4202e-02, 3.9710e-02,\n",
              "         4.4220e-01, 2.9086e-01, 3.6796e-01, 5.7584e-01, 1.3724e-01, 1.2587e-01,\n",
              "         7.6931e-01, 7.3085e-01, 6.9175e-01, 6.8430e-01, 9.6191e-02, 6.8274e-01,\n",
              "         5.2033e-01, 3.8014e-02, 3.0427e-01, 7.7037e-01],\n",
              "        [5.3961e-01, 4.9087e-01, 7.6480e-01, 8.0081e-01, 4.1258e-01, 2.0953e-01,\n",
              "         3.8601e-01, 2.6736e-01, 6.1093e-01, 6.8778e-01, 9.8046e-01, 3.3688e-01,\n",
              "         2.5752e-01, 2.8728e-01, 6.6360e-01, 9.6053e-02, 9.0198e-01, 9.0657e-01,\n",
              "         3.7712e-01, 7.7968e-01, 1.1139e-01, 9.5338e-01, 6.5317e-01, 6.6826e-01,\n",
              "         5.0724e-01, 3.9831e-01, 8.1716e-01, 1.4146e-02],\n",
              "        [7.2884e-01, 7.6061e-01, 9.0489e-01, 3.6235e-02, 9.9386e-01, 2.3383e-01,\n",
              "         6.2299e-02, 3.4774e-01, 1.6199e-01, 6.2890e-01, 5.9063e-02, 1.4138e-01,\n",
              "         4.6300e-01, 5.1878e-01, 3.5148e-01, 5.7121e-01, 5.2648e-01, 8.1260e-01,\n",
              "         6.9438e-01, 2.3771e-01, 6.9032e-01, 6.9811e-01, 4.6300e-01, 7.5712e-01,\n",
              "         7.8405e-01, 1.9935e-01, 5.9248e-01, 9.3772e-01],\n",
              "        [8.8021e-01, 4.0674e-01, 7.4084e-01, 2.5451e-01, 8.4795e-01, 4.7998e-01,\n",
              "         8.8101e-01, 3.3343e-01, 2.7713e-01, 5.7134e-01, 4.2431e-01, 1.7751e-01,\n",
              "         4.8615e-01, 3.4307e-01, 8.5988e-01, 8.5159e-01, 1.5585e-01, 4.3312e-01,\n",
              "         2.7570e-01, 8.6251e-01, 6.5356e-02, 7.3174e-01, 6.4172e-01, 3.9994e-01,\n",
              "         6.1428e-02, 2.2007e-01, 5.9171e-01, 3.9027e-01],\n",
              "        [8.0203e-01, 2.5071e-02, 7.2707e-01, 6.4375e-01, 8.4653e-01, 3.1732e-01,\n",
              "         4.0661e-01, 1.8099e-01, 2.8863e-02, 1.0567e-01, 5.1765e-01, 3.6957e-02,\n",
              "         3.6236e-01, 6.5085e-01, 1.1761e-01, 5.4766e-01, 7.4224e-01, 3.7313e-01,\n",
              "         5.8513e-01, 5.6855e-01, 8.4736e-01, 1.1494e-01, 6.4502e-01, 5.9494e-01,\n",
              "         8.1723e-01, 1.3342e-01, 8.4512e-01, 8.6474e-01],\n",
              "        [6.1149e-01, 3.0438e-01, 9.8385e-01, 9.8113e-02, 2.0821e-01, 7.2750e-01,\n",
              "         3.7992e-01, 4.9468e-01, 6.5478e-01, 5.8433e-01, 5.2753e-01, 9.5958e-01,\n",
              "         2.3178e-01, 7.9568e-01, 5.7965e-01, 1.8061e-01, 4.5266e-01, 6.0823e-02,\n",
              "         1.2261e-01, 6.3206e-01, 9.9335e-03, 6.7678e-01, 9.0849e-01, 7.0233e-01,\n",
              "         3.9428e-01, 4.4730e-01, 7.4769e-01, 4.6174e-01],\n",
              "        [1.8448e-01, 5.4502e-01, 9.8512e-01, 2.8426e-01, 7.3918e-01, 8.5195e-01,\n",
              "         6.7854e-01, 6.3393e-01, 3.4555e-01, 6.8040e-01, 9.5707e-01, 7.6920e-01,\n",
              "         7.9815e-01, 7.9473e-01, 3.7318e-02, 2.8668e-01, 9.4038e-02, 4.1182e-01,\n",
              "         6.5790e-01, 9.9974e-01, 6.3092e-01, 6.6509e-01, 3.7585e-02, 9.3816e-02,\n",
              "         3.0576e-01, 8.2739e-01, 7.5254e-01, 9.2199e-01],\n",
              "        [5.4399e-01, 6.1415e-01, 1.1693e-01, 7.1656e-01, 7.8545e-01, 5.5455e-01,\n",
              "         3.6728e-01, 8.3929e-01, 9.8610e-01, 5.8395e-01, 4.2743e-01, 9.0633e-01,\n",
              "         4.2491e-01, 4.9174e-01, 6.5014e-01, 4.4392e-01, 7.8363e-01, 5.1334e-01,\n",
              "         6.0726e-01, 1.4095e-01, 9.3419e-02, 3.3513e-01, 3.3557e-01, 1.6849e-01,\n",
              "         4.4385e-01, 5.7246e-01, 1.3321e-01, 3.4278e-01],\n",
              "        [8.5858e-01, 4.9532e-01, 4.4476e-01, 8.9882e-01, 6.3019e-01, 8.5090e-01,\n",
              "         5.4807e-01, 6.2858e-01, 6.2753e-01, 6.6131e-01, 3.1981e-01, 9.3160e-01,\n",
              "         2.8177e-02, 5.2384e-01, 5.0754e-01, 2.2104e-01, 4.7842e-01, 7.7987e-01,\n",
              "         2.8593e-01, 7.7963e-01, 9.5082e-01, 4.1403e-01, 7.1622e-01, 3.5413e-01,\n",
              "         6.3829e-01, 5.8404e-01, 6.5446e-01, 2.9232e-01],\n",
              "        [6.7577e-01, 9.8507e-01, 1.3567e-01, 4.9980e-02, 9.4636e-01, 5.1000e-01,\n",
              "         9.8901e-01, 1.7994e-01, 2.9773e-01, 6.7187e-02, 1.2034e-01, 2.7835e-01,\n",
              "         4.1336e-01, 7.4407e-01, 2.2871e-01, 9.2185e-01, 8.2226e-01, 1.0707e-01,\n",
              "         7.9229e-01, 1.9994e-01, 4.1480e-01, 7.1955e-01, 8.9645e-01, 4.2585e-01,\n",
              "         7.4032e-01, 4.6486e-02, 4.2032e-02, 6.3600e-01],\n",
              "        [2.7603e-01, 9.6424e-01, 7.5768e-01, 1.3674e-01, 5.4434e-01, 9.3808e-01,\n",
              "         4.9551e-01, 7.2259e-01, 2.3460e-01, 7.3374e-01, 5.6958e-01, 4.0690e-01,\n",
              "         1.7606e-01, 3.9627e-01, 4.6803e-01, 8.7866e-01, 6.4640e-01, 6.8765e-02,\n",
              "         1.4057e-01, 8.0758e-01, 5.4766e-01, 6.7242e-01, 2.3372e-01, 7.9236e-01,\n",
              "         6.4135e-01, 5.2648e-01, 3.0588e-01, 7.1325e-01],\n",
              "        [9.8723e-01, 6.5320e-01, 1.5208e-01, 1.2817e-01, 5.2966e-01, 4.7533e-01,\n",
              "         1.6454e-01, 6.4697e-01, 5.5037e-01, 6.9165e-01, 1.9316e-01, 9.5836e-01,\n",
              "         4.9791e-01, 1.8904e-01, 1.2654e-01, 3.2730e-01, 4.6390e-01, 1.6724e-01,\n",
              "         7.5305e-01, 5.0145e-02, 2.1934e-01, 5.9076e-02, 2.1440e-01, 9.9666e-01,\n",
              "         3.1904e-01, 8.9306e-01, 6.7419e-01, 9.8637e-01],\n",
              "        [8.0226e-01, 2.3713e-01, 3.9813e-02, 6.9725e-01, 8.8445e-01, 9.1422e-01,\n",
              "         8.7057e-01, 3.7508e-01, 3.5737e-01, 7.1435e-01, 4.7478e-01, 3.9364e-01,\n",
              "         5.9297e-01, 7.0057e-02, 7.4876e-01, 7.5085e-01, 2.7588e-02, 4.4431e-01,\n",
              "         7.5994e-01, 4.7221e-01, 6.3637e-01, 1.0996e-01, 4.2070e-01, 2.8789e-02,\n",
              "         6.5737e-01, 2.8772e-01, 2.5719e-01, 7.1335e-01],\n",
              "        [3.1594e-01, 8.6421e-01, 2.6553e-03, 8.9107e-01, 1.5348e-01, 1.9006e-01,\n",
              "         6.0080e-01, 4.9002e-01, 7.9988e-01, 7.9390e-01, 5.9085e-01, 1.6691e-01,\n",
              "         6.1131e-01, 8.7374e-01, 6.5989e-01, 9.5861e-01, 6.5386e-01, 7.8754e-02,\n",
              "         4.8604e-01, 4.1083e-01, 2.6983e-01, 1.6491e-02, 2.8187e-01, 2.0707e-01,\n",
              "         7.0232e-01, 6.6563e-01, 3.2636e-01, 3.6482e-01],\n",
              "        [2.3566e-02, 6.0387e-01, 6.3392e-01, 5.1348e-01, 5.8594e-01, 6.7541e-01,\n",
              "         9.2883e-01, 1.7359e-01, 7.9807e-01, 4.8891e-01, 4.1514e-01, 4.9271e-01,\n",
              "         2.0654e-01, 9.6337e-01, 9.9707e-01, 6.2799e-01, 8.3879e-01, 4.6757e-01,\n",
              "         4.7642e-01, 6.8633e-01, 3.2986e-01, 4.3180e-01, 8.0170e-01, 3.9039e-01,\n",
              "         9.8162e-01, 3.8083e-01, 1.3617e-01, 3.7447e-01],\n",
              "        [2.5328e-01, 2.2086e-01, 2.5068e-01, 6.3595e-01, 9.9236e-01, 1.8750e-01,\n",
              "         2.5078e-02, 8.6235e-01, 9.0155e-01, 9.3525e-01, 8.0457e-01, 6.7496e-01,\n",
              "         5.5495e-01, 4.4044e-02, 5.3664e-01, 7.2955e-01, 1.6349e-01, 9.3511e-01,\n",
              "         5.4348e-01, 5.5131e-01, 5.5605e-01, 9.3953e-01, 8.8888e-01, 3.9764e-01,\n",
              "         4.9648e-01, 8.1416e-01, 8.5343e-02, 3.5954e-01],\n",
              "        [9.9387e-01, 8.7519e-02, 8.3633e-01, 7.2853e-01, 2.3114e-01, 6.8171e-01,\n",
              "         2.3725e-01, 8.4126e-01, 1.6668e-01, 8.2532e-01, 4.8347e-01, 1.4301e-01,\n",
              "         2.9954e-01, 7.1833e-01, 4.5336e-01, 2.0850e-01, 6.4452e-01, 3.5456e-01,\n",
              "         6.5278e-01, 6.5556e-01, 1.1888e-01, 5.5783e-01, 9.6627e-01, 3.7439e-01,\n",
              "         7.5314e-01, 8.1922e-01, 6.2596e-01, 2.9801e-01],\n",
              "        [5.4987e-01, 7.9152e-02, 5.6069e-01, 3.9297e-01, 2.3423e-01, 3.4429e-01,\n",
              "         3.1464e-01, 8.4830e-01, 2.3912e-01, 5.4917e-01, 1.2400e-01, 7.4676e-01,\n",
              "         2.3615e-02, 4.3471e-01, 8.0241e-01, 9.9269e-01, 7.2687e-01, 5.3315e-01,\n",
              "         1.4259e-01, 4.9765e-01, 7.0107e-01, 9.5187e-01, 5.5052e-01, 5.4743e-01,\n",
              "         6.8380e-01, 5.0005e-01, 1.6558e-01, 7.9536e-01],\n",
              "        [4.5633e-01, 1.4862e-02, 3.4249e-01, 3.6681e-01, 9.9403e-01, 7.6835e-01,\n",
              "         1.4888e-01, 9.2762e-01, 8.3049e-02, 2.1542e-02, 4.0155e-01, 8.8004e-01,\n",
              "         7.0951e-01, 7.7148e-01, 6.9590e-02, 8.4885e-01, 7.6564e-01, 2.8387e-01,\n",
              "         7.3485e-01, 2.1284e-01, 1.4341e-01, 3.6806e-02, 7.5123e-01, 7.4174e-01,\n",
              "         8.4051e-01, 1.2508e-01, 2.1157e-01, 7.7152e-01],\n",
              "        [1.8894e-01, 5.0016e-01, 3.3258e-01, 7.2109e-01, 8.8805e-01, 3.5337e-03,\n",
              "         6.4318e-01, 1.2024e-01, 9.1250e-01, 4.5831e-01, 5.2641e-01, 1.0044e-01,\n",
              "         3.5275e-01, 6.3634e-01, 7.6284e-01, 7.0407e-02, 1.3595e-01, 2.2785e-01,\n",
              "         6.9646e-01, 2.8421e-01, 4.0433e-01, 6.6712e-01, 2.0296e-01, 3.5259e-01,\n",
              "         8.7057e-01, 5.5317e-01, 8.9755e-01, 7.4377e-01],\n",
              "        [4.2872e-01, 2.9988e-01, 8.3820e-01, 9.0031e-01, 6.7790e-01, 3.2939e-01,\n",
              "         3.2083e-02, 2.5797e-01, 4.9880e-01, 9.9799e-01, 1.7605e-01, 1.1101e-01,\n",
              "         4.4196e-01, 4.1484e-02, 8.0345e-01, 3.9100e-01, 5.0191e-01, 9.1636e-03,\n",
              "         9.6381e-01, 1.9683e-02, 6.8136e-01, 1.4433e-01, 9.2324e-01, 1.8089e-01,\n",
              "         3.3622e-02, 5.0426e-02, 6.9373e-01, 1.6839e-01],\n",
              "        [8.1220e-01, 8.8924e-01, 2.6116e-01, 4.7687e-01, 5.4814e-01, 8.5080e-01,\n",
              "         2.7212e-01, 8.1047e-02, 5.1331e-01, 2.9124e-02, 7.2849e-04, 3.1361e-01,\n",
              "         6.0813e-02, 9.1459e-03, 1.2561e-02, 9.6616e-02, 6.3384e-01, 4.1550e-01,\n",
              "         8.1038e-01, 8.7664e-01, 9.9053e-01, 2.7856e-01, 2.2623e-01, 5.5201e-01,\n",
              "         6.2354e-01, 9.5799e-01, 1.5529e-01, 9.4048e-01],\n",
              "        [3.8820e-01, 6.7944e-02, 9.4363e-01, 3.9191e-01, 7.7349e-01, 7.8085e-01,\n",
              "         8.9600e-01, 8.0729e-01, 7.9594e-01, 5.8578e-01, 4.7387e-01, 3.6115e-01,\n",
              "         1.2054e-01, 4.3983e-01, 1.2656e-01, 8.6968e-01, 1.2823e-01, 7.6895e-02,\n",
              "         8.1004e-03, 1.3922e-01, 4.6401e-01, 8.1880e-01, 1.2938e-01, 7.0829e-01,\n",
              "         2.6808e-01, 3.8240e-01, 9.7250e-01, 8.1942e-01],\n",
              "        [9.3530e-01, 1.0140e-01, 2.8587e-01, 4.2851e-01, 3.5533e-01, 2.7040e-01,\n",
              "         4.2818e-01, 5.6249e-01, 5.4272e-02, 5.3254e-01, 9.6801e-01, 3.3883e-01,\n",
              "         2.3158e-01, 5.3569e-01, 4.0607e-01, 5.9517e-01, 3.2007e-01, 2.3340e-01,\n",
              "         4.1571e-01, 6.1186e-01, 9.0031e-01, 4.0453e-01, 7.0523e-01, 9.1534e-01,\n",
              "         9.7477e-01, 4.1623e-01, 6.0573e-01, 7.5336e-01],\n",
              "        [2.1033e-02, 1.4685e-01, 6.5938e-01, 8.6680e-01, 3.4910e-01, 4.8132e-01,\n",
              "         5.1935e-02, 9.0975e-01, 8.2972e-01, 2.3691e-01, 5.0096e-01, 4.8121e-01,\n",
              "         5.9242e-01, 2.7646e-01, 2.8509e-02, 3.5166e-01, 2.1856e-01, 1.0468e-01,\n",
              "         6.7384e-02, 7.6556e-01, 6.7913e-01, 5.5197e-01, 7.6961e-01, 6.5574e-01,\n",
              "         5.7704e-01, 2.8720e-01, 6.5351e-02, 2.7691e-01],\n",
              "        [3.5838e-01, 2.3302e-01, 1.6574e-01, 6.8690e-01, 5.1327e-01, 8.3176e-01,\n",
              "         4.8574e-01, 6.7934e-01, 2.3569e-01, 7.9006e-02, 3.1019e-01, 8.5792e-01,\n",
              "         9.4387e-01, 7.0029e-01, 9.3277e-01, 9.1151e-01, 7.6047e-02, 3.0278e-01,\n",
              "         1.2538e-01, 1.2949e-01, 7.3790e-01, 5.2149e-01, 3.6930e-01, 9.6020e-01,\n",
              "         5.4334e-01, 8.3311e-01, 1.4716e-01, 1.6351e-01],\n",
              "        [4.0329e-01, 8.3662e-01, 4.6507e-01, 9.3568e-01, 7.3651e-01, 1.8997e-01,\n",
              "         4.9666e-01, 7.7139e-01, 1.8154e-01, 3.2118e-01, 4.8578e-01, 3.9085e-01,\n",
              "         5.3863e-02, 8.0757e-01, 9.3037e-01, 9.5418e-02, 1.5246e-01, 2.7889e-03,\n",
              "         8.5359e-01, 8.0068e-01, 8.5354e-01, 2.5121e-01, 4.3857e-01, 3.8333e-01,\n",
              "         5.7649e-01, 9.1539e-01, 2.5794e-01, 8.2139e-01],\n",
              "        [3.1791e-01, 5.8204e-01, 5.3025e-01, 9.2470e-01, 4.2525e-01, 8.0433e-01,\n",
              "         9.1656e-01, 2.4682e-01, 1.8500e-01, 7.1990e-01, 1.5672e-01, 9.3935e-01,\n",
              "         5.8039e-01, 2.7725e-01, 6.2103e-01, 7.8440e-01, 3.5570e-01, 9.1869e-01,\n",
              "         7.2223e-02, 6.5822e-01, 9.5712e-02, 1.7120e-01, 2.0459e-01, 2.9169e-01,\n",
              "         9.3166e-01, 8.2134e-01, 6.3463e-01, 2.5826e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to Display the Second Image?"
      ],
      "metadata": {
        "id": "4hQq5SBRhfOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(second_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "Rsz-lcIihmCn",
        "outputId": "21cd1301-13e2-4f31-f0ba-cf26daf926f6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Manipulation"
      ],
      "metadata": {
        "id": "udjHEQSDlkrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1,1],[1,0]])\n",
        "print(a)\n",
        "print(torch.matrix_power(a,2)) # Matrix Multiplication\n",
        "print(torch.matrix_power(a,3))\n",
        "print(torch.matrix_power(a,4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QySPyIR9ln6e",
        "outputId": "0101b36b-2bee-467e-e789-a8e2f0452b88"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1],\n",
            "        [1, 0]])\n",
            "tensor([[2, 1],\n",
            "        [1, 1]])\n",
            "tensor([[3, 2],\n",
            "        [2, 1]])\n",
            "tensor([[5, 3],\n",
            "        [3, 2]])\n"
          ]
        }
      ]
    }
  ]
}